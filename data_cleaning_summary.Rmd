---
title: "Mid term EDA"
author: "Yingmai Chen"
date: "2023-11-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggplot2)
library(readxl)
library(stringr)
```

# data clean for cencus

```{r}
total2020<-read_excel("total_2020.xls")
total2021<-read_excel("total_2021.xls")
total2020<- total2020 %>%
  mutate(Geography = str_sub(Geography, 1, -4))%>%
 mutate(`Geographic Area Name` = str_replace(`Geographic Area Name`, ".*?,\\s*", ""))
total2021<- total2021 %>%
  mutate(Geography = str_sub(Geography, 1, -4))%>%
mutate(`Geographic Area Name` = str_replace(`Geographic Area Name`, ".*?,\\s*", ""))
```
# I calculate the average population of all cities in each state
```{r}
total2020_processed <- total2020 %>%
  mutate(Geography = str_sub(Geography, 1, -4)) %>%
  mutate(`Geographic Area Name` = str_replace(`Geographic Area Name`, ".*?,\\s*", ""))

total2021_processed <- total2021 %>%
  mutate(Geography = str_sub(Geography, 1, -4)) %>%
  mutate(`Geographic Area Name` = str_replace(`Geographic Area Name`, ".*?,\\s*", ""))

# Assuming 'Total Population' and 'poverty' are column names in your data
# Combine the two data sets and calculate mean for 'Total Population' and 'poverty'
combined_data <- bind_rows(total2020_processed, total2021_processed, .id = "year") %>%
  group_by(`Geographic Area Name`) %>%
  summarise(
    Mean_Total_Population = mean(`Total population`, na.rm = TRUE),
    Mean_poverty = mean(poverty, na.rm = TRUE),
    .groups = 'drop' 
  )
```

```{r}
us_state_abbreviations <- data.frame(
  State = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado",
            "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", 
            "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", 
            "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", 
            "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", 
            "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", 
            "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", 
            "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", 
            "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming"),
  Abbreviation = c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", "HI", "ID", 
                   "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", "MA", "MI", "MN", 
                   "MS", "MO", "MT", "NE", "NV", "NH", "NJ", "NM", "NY", "NC", "ND", 
                   "OH", "OK", "OR", "PA", "RI", "SC", "SD", "TN", "TX", "UT", "VT", 
                   "VA", "WA", "WV", "WI", "WY")
)

combined_data <- combined_data %>%
  left_join(us_state_abbreviations, by = c("Geographic Area Name" = "State")) %>%
  # Remove the full state name column if you don't need it
  select(-`Geographic Area Name`) %>%
  # Rename Abbreviation to State or another name if you prefer
  rename(State = Abbreviation)

f_data <- combined_data %>%
  filter(State %in% c("KY", "ND", "WA", "WV", "TX", "LA", "TN", "OR", "WI", "AZ", "VT", "PR", "HI"))
f_data <- f_data %>%
  rename(state = State)
state_summary <- merge(floods_by_state, f_data, by = "state")

```

# data clean for floods

```{r}
disaster_summaries<-read.csv("DisasterDeclarationsSummaries.csv")
fema_summaries<-read.csv("FemaWebDisasterSummaries.csv")
flood_data <- disaster_summaries %>%
  filter(incidentType == "Flood", between(fyDeclared, 2020, 2021))
merged_data <- left_join(flood_data, fema_summaries, by = "disasterNumber")
glimpse(merged_data)
```
```{r}
# Assuming merged_data and f_data are already in your R environment

# Write merged_data to a CSV file
write.csv(merged_data, "merged_data.csv", row.names = FALSE)

# Write f_data to a CSV file (replace f_data with the actual name of your dataframe)
write.csv(f_data, "f_data.csv", row.names = FALSE)

```

# EDA - Exploratory Data Analysis

# Summary statistics for FEMA(by state)

```{r warning=FALSE}
floods_by_state <- merged_data %>%
  group_by(state) %>%
  summarise(n = n(), .groups = 'drop')  # Ensuring that the resulting data frame will be ungrouped

# Now, you can plot the data
ggplot(floods_by_state, aes(x = reorder(state, n), y = n, fill = n)) +
  geom_bar(stat = "identity") +
  coord_flip() + # Flip coordinates for horizontal bars
  scale_fill_viridis_c() + # Use the viridis color scale
  labs(title = "Number of Flood Events by State", x = "State", y = "Number of Events") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    legend.title = element_blank(),
    legend.position = "bottom"
  ) +
  guides(fill = FALSE)  # Remove the color guide
# Save the enhanced plot
ggsave("number_of_floods_by_state_enhanced.png", width = 10, height = 8, dpi = 300)

```
Based on data,we can find KY state has the Most flood accidents.
# Summary statistics for FEMA(by reasons)

```{r}
# Group and summarise as before
grouped_data <- merged_data %>%
  group_by(declarationTitle) %>%
  summarise(Count = n(), .groups = 'drop')

# Filter for the top N declaration titles based on count
top_n_titles <- grouped_data %>%
  top_n(10, Count) # Adjust the number 10 to show more or fewer categories

custom_colors <- c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b",
                   "#e377c2", "#7f7f7f", "#bcbd22", "#17becf")

ggplot(top_n_titles, aes(x = reorder(declarationTitle, Count), y = Count, fill = declarationTitle)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  scale_fill_manual(values = custom_colors) + # Use custom colors
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Top Flood Declarations by Title", x = "Count", y = "Declaration Title") +
  theme(plot.title = element_text(size = 14, face = "bold"),
        axis.title.x = element_text(size = 12, face = "bold"),
        axis.title.y = element_text(size = 12, face = "bold"),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10))
```
Finally, I found the reason of floods mostly Severe storm,flooding,landslides and mudslides,from the data given by FEMA.
#  cencus
```{r}
f_data_ordered_population <- f_data %>%
  arrange(desc(Mean_Total_Population))

ggplot(f_data_ordered_population, aes(x = reorder(state, Mean_Total_Population), y = Mean_Total_Population, fill = Mean_Total_Population)) + 
  geom_bar(stat = "identity") +
  coord_flip() + # Flip coordinates for horizontal bars
  scale_fill_viridis_c(option = "C") + # Use a viridis color scale for a visually appealing palette
  labs(title = "Mean Total Population by State",
       x = "State", 
       y = "Mean Total Population") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```
based on the data of total population,I find AZ has the highest mean value of total population by state. 
```{r}
f_data_ordered_poverty <- f_data %>%
  arrange(desc(Mean_poverty))

ggplot(f_data_ordered_poverty, aes(x = reorder(state, Mean_poverty), y = Mean_poverty, fill = Mean_poverty)) + 
  geom_bar(stat = "identity") +
  coord_flip() + # Flip coordinates for horizontal bars
  scale_fill_viridis_c(option = "M") + # Use a viridis color scale for a visually appealing palette
  labs(title = "Mean Poverty by State",
       x = "State", 
       y = "Mean Poverty") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(hjust = 0.5))
```
There has the same patterns with total population.
# merge cencus and FEMA
```{r}
ggplot(state_summary, aes(x = Mean_Total_Population, y = n)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship Between Number of Floods and Mean Total Population by State",
       x = "Mean Total Population",
       y = "Number of Floods")
```
So finally I don't find there has a relationship between mean total population and number of floods.
